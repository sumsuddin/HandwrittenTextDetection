{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "\n",
    "sys.path.append('src')\n",
    "from ocr.normalization import word_normalization, letter_normalization\n",
    "from ocr import page, words\n",
    "from ocr.helpers import implt, resize\n",
    "from ocr.tfhelpers import Model\n",
    "from ocr.datahelpers import idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG = 'data/pages/test2.jpg'    # 1, 2, 3\n",
    "LANG = 'en'\n",
    "USE_DICTIONARY = True\n",
    "MODEL_LOC_CTC = 'models/word-clas/CTC/Classifier1-19500'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTC_MODEL = Model(MODEL_LOC_CTC, 'word_prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers For Dictionary Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Words\n",
    "WORDS = {}\n",
    "with open('data/dictionaries/' + LANG + '_50k.txt') as f:\n",
    "    for line in f:\n",
    "        if LANG == 'en':\n",
    "            WORDS[unidecode.unidecode(line.split(\" \")[0])] = int(line.split(\" \")[1])\n",
    "        else:\n",
    "            WORDS[line.split(\" \")[0]] = int(line.split(\" \")[1])\n",
    "WORDS = Counter(WORDS)\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of word.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    if word in WORDS:\n",
    "        return word\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of words that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    \n",
    "    if LANG == 'cz':\n",
    "        letters = 'aábcčdďeéěfghiíjklmnňoópqrřsštťuúůvwxyýzž'\n",
    "    else:\n",
    "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(cv2.imread(IMG), cv2.COLOR_BGR2RGB)\n",
    "implt(image)\n",
    "# Crop image and get bounding boxes\n",
    "crop = page.detection(image)\n",
    "implt(crop)\n",
    "boxes = words.detection(crop)\n",
    "lines = words.sort_words(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition Using CTC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognise(img):\n",
    "    \"\"\"Recognising words using CTC Model.\"\"\"\n",
    "    img = word_normalization(\n",
    "        img,\n",
    "        64,\n",
    "        border=False,\n",
    "        tilt=False,\n",
    "        hyst_norm=False)\n",
    "    length = img.shape[1]\n",
    "    # Input has shape [batch_size, height, width, 1]\n",
    "    input_imgs = np.zeros(\n",
    "            (1, 64, length, 1), dtype=np.uint8)\n",
    "    input_imgs[0][:, :length, 0] = img\n",
    "\n",
    "    pred = CTC_MODEL.eval_feed({\n",
    "        'inputs:0': input_imgs,\n",
    "        'inputs_length:0': [length],\n",
    "        'keep_prob:0': 1})[0]\n",
    "\n",
    "    word = ''\n",
    "    for i in pred:\n",
    "        word += idx2char(i)\n",
    "    if USE_DICTIONARY:\n",
    "        word = correction(word.lower())\n",
    "    return word\n",
    "\n",
    "implt(crop)\n",
    "for line in lines:\n",
    "    print(\" \".join([recognise(crop[y1:y2, x1:x2]) for (x1, y1, x2, y2) in line]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
